@article{Melton2020-ke,
	author = {Melton, Joe R and Arora, Vivek K and Wisernig-Cojoc, Eduard and Seiler, Christian and Fortier, Matthew and Chan, Ed and Teckentrup, Lina},
	journal = {Geoscientific Model Development},
	number = {6},
	pages = {2825--2850},
	publisher = {Copernicus GmbH},
	title = {CLASSIC v1. 0: the open-source community successor to the Canadian Land Surface Scheme (CLASS) and the Canadian Terrestrial Ecosystem Model (CTEM)--Part 1: Model framework and site-level performance},
	volume = {13},
	year = {2020}
}

@article{Collier2018-th,
	abstract = {Abstract The increasing complexity of Earth system models has
              inspired efforts to quantitatively assess model fidelity through
              rigorous comparison with best available measurements and
              observational data products. Earth system models exhibit a high
              degree of spread in predictions of land biogeochemistry,
              biogeophysics, and hydrology, which are sensitive to forcing from
              other model components. Based on insights from prior land model
              evaluation studies and community workshops, the authors developed
              an open source model benchmarking software package that generates
              graphical diagnostics and scores model performance in support of
              the International Land Model Benchmarking (ILAMB) project.
              Employing a suite of in situ, remote sensing, and reanalysis data
              sets, the ILAMB package performs comprehensive model assessment
              across a wide range of land variables and generates a
              hierarchical set of web pages containing statistical analyses and
              figures designed to provide the user insights into strengths and
              weaknesses of multiple models or model versions. Described here
              is the benchmarking philosophy and mathematical methodology
              embodied in the most recent implementation of the ILAMB package.
              Comparison methods unique to a few specific data sets are
              presented, and guidelines for configuring an ILAMB analysis and
              interpreting resulting model performance scores are discussed.
              ILAMB is being adopted by modeling teams and centers during model
              development and for model intercomparison projects, and community
              engagement is sought for extending evaluation metrics and adding
              new observational data sets to the benchmarking framework.},
	author = {Collier, Nathan and Hoffman, Forrest M and Lawrence, David M and Keppel‚ÄêAleks, Gretchen and Koven, Charles D and Riley, William J and Mu, Mingquan and Randerson, James T},
	journal = {J. Adv. Model. Earth Syst.},
	month = nov,
	number = 11,
	pages = {2731--2754},
	title = {The International Land Model Benchmarking ({ILAMB}) System: Design, Theory, and Implementation},
	volume = 10,
	year = 2018
}

